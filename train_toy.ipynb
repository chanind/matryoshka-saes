{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from toy_model import Tree, TreeDataset\n",
    "import json\n",
    "\n",
    "\n",
    "DEVICE = 'cpu'\n",
    "\n",
    "\n",
    "tree_dict = json.load(open('./tree.json', 'r'))\n",
    "\n",
    "tree = Tree(tree_dict=tree_dict)\n",
    "\n",
    "D_MODEL = tree.n_features\n",
    "\n",
    "matryoshka_config = {\n",
    "    'n_latents': tree.n_features,\n",
    "    'target_l0': 1.2338, # L0 of the true features\n",
    "    'n_prefixes': 10,\n",
    "    'd_model': D_MODEL,\n",
    "    'n_steps': 50000,\n",
    "    'lr': 3e-2,\n",
    "    'permute_latents': True,\n",
    "    'sparsity_type': 'l1',\n",
    "    'starting_sparsity_loss_scale': 0.2\n",
    "}\n",
    "\n",
    "\n",
    "vanilla_config = matryoshka_config | {'n_prefixes': 1, 'permute_latents': False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "@torch.no_grad()\n",
    "def get_latent_perm(sae, tree_ds, include_all_latents=False):\n",
    "    '''\n",
    "    Get permutation of sae latents that tries to assign each latent to its closest-matching ground-truth feature\n",
    "    '''\n",
    "    global DEVICE\n",
    "    sample = tree_ds.tree.sample(1000).to(DEVICE)\n",
    "    x = sample @ tree_ds.true_feats.to(DEVICE)\n",
    "    \n",
    "    feat_norms = tree_ds.true_feats.norm(dim=-1).to(DEVICE)\n",
    "    scaled_sample = sample * feat_norms[None, :]\n",
    "\n",
    "    true_acts = scaled_sample\n",
    "    true_acts = true_acts/true_acts.max(dim=0, keepdim=True).values.clamp(min=1e-10)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        sae_acts = sae.get_acts(x)\n",
    "        sae_acts = sae_acts/sae_acts.max(dim=0, keepdim=True).values.clamp(min=1e-10)\n",
    "        sims = (sae_acts.T @ true_acts).cpu()\n",
    "\n",
    "    max_value = sims.max()\n",
    "    cost_matrix = max_value - sims\n",
    "\n",
    "    row_ind, col_ind = row_ind, col_ind = linear_sum_assignment(cost_matrix.detach().cpu().numpy().T)\n",
    "    leftover_features = np.array(list({i for i in range(sims.shape[0]) if sae_acts.max(dim=0).values[i] > 0} - set(col_ind))).astype(int)\n",
    "    \n",
    "    if include_all_latents:\n",
    "        return torch.tensor(np.concatenate([col_ind, leftover_features]))\n",
    "    else:\n",
    "        return torch.tensor(col_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from sae import MatryoshkaSAE\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Get true_feats\n",
    "true_feats = (torch.randn(tree.n_features, D_MODEL)/np.sqrt(D_MODEL)).to(DEVICE)\n",
    "\n",
    "# Generate random orthogonal directions by taking QR decomposition of random matrix\n",
    "Q, R = torch.linalg.qr(torch.randn(D_MODEL, D_MODEL))\n",
    "true_feats = Q[:tree.n_features].to(DEVICE)\n",
    "\n",
    "\n",
    "random_scaling = 1+torch.randn(tree.n_features, device=DEVICE)* 0.05\n",
    "true_feats *= random_scaling[:, None]\n",
    "\n",
    "\n",
    "dataset = TreeDataset(tree, true_feats.cpu(), batch_size=200, num_batches=vanilla_config['n_steps'])\n",
    "dataloader = DataLoader(dataset, batch_size=None, num_workers=6, pin_memory=True)\n",
    "\n",
    "ref_acts = dataset.tree.sample(100).to(DEVICE)\n",
    "ref_x = ref_acts @ dataset.true_feats.to(DEVICE)\n",
    "ref_acts = ref_acts*random_scaling[None]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "from heatmap import heatmap\n",
    "\n",
    "\n",
    "vanilla_sae = MatryoshkaSAE(**vanilla_config).to(DEVICE)\n",
    "matryoshka_sae = MatryoshkaSAE(**matryoshka_config).to(DEVICE)\n",
    "\n",
    "for step, batch in tqdm(enumerate(dataloader), total=vanilla_config['n_steps']):\n",
    "    batch = batch.to(DEVICE)\n",
    "\n",
    "    matryoshka_sae.step(batch)\n",
    "    vanilla_sae.step(batch)\n",
    "\n",
    "    if step % 300 == 0:\n",
    "        clear_output(wait=True)\n",
    "    \n",
    "        heatmap(ref_acts.cpu(), title='Ground-Truth Features').show()\n",
    "\n",
    "        matryoshka_perm = get_latent_perm(matryoshka_sae, dataset)\n",
    "        heatmap(matryoshka_sae.get_acts(ref_x)[:,matryoshka_perm].cpu(), title=f'Matryoshka Latents  |  Sparsity Reg: {matryoshka_sae.sparsity_controller():.2f}  |  Step {step}',).show()\n",
    "\n",
    "        vanilla_perm = get_latent_perm(vanilla_sae, dataset)\n",
    "        heatmap(vanilla_sae.get_acts(ref_x)[:,vanilla_perm].cpu(), title=f'Vanilla Latents  |  Sparsity Reg: {vanilla_sae.sparsity_controller():.2f}  |  Step {step}').show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tokre",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
